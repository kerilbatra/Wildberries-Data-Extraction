{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dec2adf-fe65-4b65-afe4-7eb39e1e1220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved successfully!\n",
      "Data saved to Excel at C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\salesquanity.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Wildberries API - Analytics Sales by Regions\n",
    "url = \"https://seller-analytics-api.wildberries.ru/api/v1/analytics/region-sale\"  # SALES WITH QUANTITY\n",
    "\n",
    "# Token for authentication\n",
    "token = \"eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjQxMTE4djEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc0Nzg1NjQ0NywiaWQiOiIwMTkzNDg4NC00MDUzLTdjYWItOTJlNy01MjJiNTliZjQwNzEiLCJpaWQiOjYzNzM3MTQsIm9pZCI6NzQyNTYsInMiOjM2LCJzaWQiOiIzYWU4NTRhYy1kMDU5LTVmZjQtYmMwYy0zNjZkNTQ1ZjFlOTAiLCJ0IjpmYWxzZSwidWlkIjo2MzczNzE0fQ.CgFXOtqtBiYALCpqFKubFr0Yt6gE6udEk3WmDVQ_WFTr602mkyGceI6GURLe9ik0O_L56ad1B1ZpNphH_uYVRg\"\n",
    "\n",
    "# Set up headers with the authorization token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "\n",
    "# Calculate dateFrom (10 days before today) and dateTo (1 day before today)\n",
    "current_date = datetime.now()\n",
    "date_from = (current_date - timedelta(days=10)).strftime(\"%Y-%m-%d\")\n",
    "date_to = (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the dateFrom and dateTo parameters\n",
    "params = {\n",
    "    \"dateFrom\": date_from,  \n",
    "    \"dateTo\": date_to \n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make the GET request to the API with the date parameters\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  # Raise an error for HTTP codes 4xx/5xx\n",
    "\n",
    "    # Check the response content\n",
    "    data = response.json()\n",
    "    print(\"Data retrieved successfully!\")\n",
    "\n",
    "    # Extract the 'report' list from the data\n",
    "    report_data = data.get('report', [])\n",
    "\n",
    "    if report_data:\n",
    "        # Convert the report data to a DataFrame\n",
    "        df = pd.DataFrame(report_data)\n",
    "\n",
    "        # Add a column for the actual date when the code runs\n",
    "        run_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        df['RunDate'] = run_date\n",
    "\n",
    "        # Save the DataFrame to an Excel file\n",
    "        output_path = r'C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\salesquanity.xlsx'\n",
    "        df.to_excel(output_path, index=False)\n",
    "        print(f\"Data saved to Excel at {output_path}.\")\n",
    "    else:\n",
    "        print(\"No report data found in the API response.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred while making the API request: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"An error occurred while processing the API response: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46636f9-e1cd-424f-b3c1-5052dd7e2332",
   "metadata": {},
   "source": [
    "# UPLOADING API DATA TO SHAREPOINT WITHOUT DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a6aef6-4995-4d6b-a98c-85c095e8b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file has been downloaded from SharePoint.\n",
      "Existing data loaded into DataFrame.\n",
      "New data loaded into DataFrame.\n",
      "New data merged with existing data successfully.\n",
      "Data has been successfully written to the Excel file without duplicates.\n",
      "File has been uploaded back to SharePoint.\n",
      "Local file has been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "\n",
    "# SharePoint link and file details\n",
    "site_url = 'https://herbion.sharepoint.com/sites/PowerBI/'\n",
    "doc_library = '/sites/PowerBI/Shared Documents/Uzbekistan Uzum'\n",
    "file_name = 'RussiaSalesQuantity.xlsx'\n",
    "\n",
    "# Credentials\n",
    "username = 'developer.bi@herbion.org'\n",
    "password = 'Q$577452978591up'\n",
    "\n",
    "# Define the path to your local Excel file containing the new data\n",
    "new_data_file_path = r\"C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\salesquanity.xlsx\"\n",
    "\n",
    "# Define the columns to check for duplicates\n",
    "subset_columns = ['cityName', 'countryName', 'foName', 'nmID', 'regionName',\n",
    "                 'sa', 'saleInvoiceCostPrice', 'saleInvoiceCostPricePerc', 'saleItemInvoiceQty', 'RunDate']\n",
    "\n",
    "try:\n",
    "    # Authenticate to SharePoint\n",
    "    auth_ctx = AuthenticationContext(site_url)\n",
    "    if not auth_ctx.acquire_token_for_user(username, password):\n",
    "        print(f\"Error acquiring token: {auth_ctx.get_last_error()}\")\n",
    "        exit(1)\n",
    "\n",
    "    ctx = ClientContext(site_url, auth_ctx)\n",
    "\n",
    "    # Download the existing file from SharePoint\n",
    "    response = File.open_binary(ctx, f\"{doc_library}/{file_name}\")\n",
    "\n",
    "    # Write the response content to a local file\n",
    "    with open(file_name, \"wb\") as existing_file:\n",
    "        existing_file.write(response.content)\n",
    "\n",
    "    print(\"Existing file has been downloaded from SharePoint.\")\n",
    "\n",
    "    # Load the existing data into a DataFrame\n",
    "    try:\n",
    "        existing_df = pd.read_excel(file_name)\n",
    "        print(\"Existing data loaded into DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during file download for existing data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the new data into a DataFrame\n",
    "try:\n",
    "    df = pd.read_excel(new_data_file_path)\n",
    "    print(\"New data loaded into DataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading new data from the file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Combine the existing data with the new data\n",
    "try:\n",
    "    # Combine and deduplicate based on the subset columns\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset=subset_columns)\n",
    "    print(\"New data merged with existing data successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the new rows added after combining\n",
    "new_rows = combined_df[len(existing_df):]\n",
    "\n",
    "if new_rows.empty:\n",
    "    print(\"No new rows to add.\")\n",
    "else:\n",
    "    # Append the new rows to the Excel sheet\n",
    "    try:\n",
    "        book = load_workbook(file_name)\n",
    "        sheet = book['Sheet1']  # Ensure this matches your sheet name\n",
    "        for row in new_rows.itertuples(index=False, name=None):\n",
    "            sheet.append(row)\n",
    "\n",
    "        # Save the modified file\n",
    "        book.save(file_name)\n",
    "        print(\"Data has been successfully written to the Excel file without duplicates.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the Excel file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Upload the updated file back to SharePoint\n",
    "    try:\n",
    "        with open(file_name, 'rb') as content_file:\n",
    "            file_content = content_file.read()\n",
    "\n",
    "        File.save_binary(ctx, f\"{doc_library}/{file_name}\", file_content)\n",
    "        print(\"File has been uploaded back to SharePoint.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during file upload: {e}\")\n",
    "\n",
    "# Cleanup: Remove the local file\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "    print(\"Local file has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04d3b1-4e10-4552-ad8c-66fe87de7258",
   "metadata": {},
   "source": [
    "# SALES with DATE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c710f6df-756b-4aaa-97f1-32ba129c5656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved successfully!\n",
      "Data saved to Excel at C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\SalesMERGE.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "url = \"https://statistics-api.wildberries.ru/api/v1/supplier/sales\"\n",
    "\n",
    "# TOKEN FROM WILDBERRIES WEBSITE.\n",
    "token = \"eyJhbGciOiJFUzI1NiIsImtpZCI6IjIwMjQxMTE4djEiLCJ0eXAiOiJKV1QifQ.eyJlbnQiOjEsImV4cCI6MTc0Nzg1NjQ0NywiaWQiOiIwMTkzNDg4NC00MDUzLTdjYWItOTJlNy01MjJiNTliZjQwNzEiLCJpaWQiOjYzNzM3MTQsIm9pZCI6NzQyNTYsInMiOjM2LCJzaWQiOiIzYWU4NTRhYy1kMDU5LTVmZjQtYmMwYy0zNjZkNTQ1ZjFlOTAiLCJ0IjpmYWxzZSwidWlkIjo2MzczNzE0fQ.CgFXOtqtBiYALCpqFKubFr0Yt6gE6udEk3WmDVQ_WFTr602mkyGceI6GURLe9ik0O_L56ad1B1ZpNphH_uYVRg\"\n",
    "\n",
    "# Set up headers with the authorization token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "\n",
    "# Calculate dateFrom (10 days before today) and dateTo (1 day before today)\n",
    "current_date = datetime.now()\n",
    "date_from = (current_date - timedelta(days=10)).strftime(\"%Y-%m-%d\")\n",
    "date_to = (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the dynamic date parameters\n",
    "params = {\n",
    "    \"dateFrom\": date_from, \n",
    "    \"dateTo\": date_to\n",
    "}\n",
    "\n",
    "# Make the GET request to the API with the date parameters\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Data retrieved successfully!\")\n",
    "\n",
    "    # Convert the data to a pandas DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Add a column for the actual date when the code runs\n",
    "    run_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    df['RunDate'] = run_date\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    output_path = r'C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\SalesMERGE.xlsx'\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to Excel at {output_path}.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415c209-2504-42e3-b352-41ec54769753",
   "metadata": {},
   "source": [
    "# UPLOADING API DATA TO SHAREPOINT WITHOUT DUPLICATES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b047ed0-7307-41e3-8c4e-3dedd4ee4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file has been downloaded from SharePoint.\n",
      "Existing data loaded into DataFrame.\n",
      "Existing Data (First 5 rows):\n",
      "                  date       lastChangeDate warehouseName warehouseType  \\\n",
      "0  2024-11-30T19:14:17  2024-12-01T06:06:54      Коледино      Склад WB   \n",
      "1  2024-12-01T08:35:10  2024-12-01T08:43:18      Коледино      Склад WB   \n",
      "2  2024-12-01T10:10:47  2024-12-01T10:18:04      Коледино      Склад WB   \n",
      "3  2024-12-01T10:48:27  2024-12-01T10:56:27  Электросталь      Склад WB   \n",
      "4  2024-12-01T11:51:18  2024-12-01T11:58:27  Электросталь      Склад WB   \n",
      "\n",
      "  countryName                oblastOkrugName  \\\n",
      "0    Беларусь                            NaN   \n",
      "1      Россия    Уральский федеральный округ   \n",
      "2      Россия  Центральный федеральный округ   \n",
      "3      Россия  Центральный федеральный округ   \n",
      "4      Россия        Южный федеральный округ   \n",
      "\n",
      "                          regionName supplierArticle       nmId  \\\n",
      "0                Могилёвская область     00-00000093  214889122   \n",
      "1  Ханты-Мансийский автономный округ    00-000000650   44056938   \n",
      "2                  Калужская область    00-000000630   44068158   \n",
      "3                Воронежская область     00-00000086  164099764   \n",
      "4                 Краснодарский край     00-00000103  270583087   \n",
      "\n",
      "         barcode  ... paymentSaleAmount  forPay finishedPrice  priceWithDisc  \\\n",
      "0  8964001203261  ...                 0  177.96        206.36          229.6   \n",
      "1  4607006676756  ...                 7  175.24        196.00          226.0   \n",
      "2  4607006673892  ...                 0  180.53        209.00          233.0   \n",
      "3  8964002385096  ...                 0  161.20        181.00          208.0   \n",
      "4  8964002387069  ...                 0  581.25        510.00          750.0   \n",
      "\n",
      "         saleID   orderType       sticker               gNumber  \\\n",
      "0  S14083577156  Клиентский           NaN   3981221177198844442   \n",
      "1  S14085898395  Клиентский  1.645452e+10  95163111772422074507   \n",
      "2  S14086857044  Клиентский  1.645452e+10   1732869885768358775   \n",
      "3  S14087647931  Клиентский           NaN  92019286197079639320   \n",
      "4  S14089289320  Клиентский  2.346744e+10   5630610564505817220   \n",
      "\n",
      "                                       srid     RunDate  \n",
      "0  d2.r9c8c5f36f2604bc2985d3303e883c666.0.0  2024-12-31  \n",
      "1                     34445644600868901.1.0  2024-12-31  \n",
      "2                   8697960761217531994.0.0  2024-12-31  \n",
      "3   dT.b7769c2bce3142599b483c81f4981211.5.0  2024-12-31  \n",
      "4                   5637655563640266449.0.0  2024-12-31  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "New data loaded into DataFrame.\n",
      "New data merged with existing data successfully.\n",
      "Data has been successfully written to the Excel file without duplicates.\n",
      "File has been uploaded back to SharePoint.\n",
      "Local file has been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "\n",
    "# SharePoint link and file details\n",
    "site_url = 'https://herbion.sharepoint.com/sites/PowerBI/'\n",
    "doc_library = '/sites/PowerBI/Shared Documents/Uzbekistan Uzum'\n",
    "file_name = 'RussiaSales.xlsx' # RUSSIA SALES WITH DATE\n",
    "\n",
    "# Credentials\n",
    "username = 'developer.bi@herbion.org'\n",
    "password = 'Q$577452978591up'\n",
    "\n",
    "# Define the path to your local Excel file containing the new data\n",
    "new_data_file_path = r\"C:\\Users\\keril.batra\\OneDrive - Herbion\\Desktop\\E-Commerce\\Russia E-Commerce\\SalesMERGE.xlsx\"\n",
    "\n",
    "# Define the columns to check for duplicates\n",
    "subset_columns = ['date', 'lastChangeDate', 'warehouseName', 'warehouseType', 'countryName', 'oblastOkrugName',\t'regionName',\t\n",
    "                  'supplierArticle', 'nmId', 'barcode',\t'category',\t'subject', 'brand',\t'techSize',\t'incomeID',\t'isSupply',\t'isRealization',\t\n",
    "                  'totalPrice', 'discountPercent', 'spp', 'paymentSaleAmount', 'forPay', 'finishedPrice', 'priceWithDisc', 'saleID',\t\n",
    "                  'orderType', 'sticker', 'gNumber', 'srid', 'RunDate']\n",
    "\n",
    "try:\n",
    "    # Authenticate to SharePoint\n",
    "    auth_ctx = AuthenticationContext(site_url)\n",
    "    if not auth_ctx.acquire_token_for_user(username, password):\n",
    "        print(f\"Error acquiring token: {auth_ctx.get_last_error()}\")\n",
    "        exit(1)\n",
    "\n",
    "    ctx = ClientContext(site_url, auth_ctx)\n",
    "\n",
    "    # Download the existing file from SharePoint\n",
    "    response = File.open_binary(ctx, f\"{doc_library}/{file_name}\")\n",
    "\n",
    "    # Write the response content to a local file\n",
    "    with open(file_name, \"wb\") as existing_file:\n",
    "        existing_file.write(response.content)\n",
    "\n",
    "    print(\"Existing file has been downloaded from SharePoint.\")\n",
    "\n",
    "    # Load the existing data into a DataFrame\n",
    "    try:\n",
    "        existing_df = pd.read_excel(file_name)\n",
    "        print(\"Existing data loaded into DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Debugging: Check the first few rows of the existing data\n",
    "    print(\"Existing Data (First 5 rows):\")\n",
    "    print(existing_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during file download for existing data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the new data into a DataFrame\n",
    "try:\n",
    "    df = pd.read_excel(new_data_file_path)\n",
    "    print(\"New data loaded into DataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading new data from the file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Combine the existing data with the new data\n",
    "try:\n",
    "    # Combine and deduplicate based on the subset columns\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates(subset=subset_columns)\n",
    "    print(\"New data merged with existing data successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the new rows added after combining\n",
    "new_rows = combined_df[len(existing_df):]\n",
    "\n",
    "if new_rows.empty:\n",
    "    print(\"No new rows to add.\")\n",
    "else:\n",
    "    # Append the new rows to the Excel sheet\n",
    "    try:\n",
    "        book = load_workbook(file_name)\n",
    "        sheet = book['Sheet1']  # Ensure this matches your sheet name\n",
    "        for row in new_rows.itertuples(index=False, name=None):\n",
    "            sheet.append(row)\n",
    "\n",
    "        # Save the modified file\n",
    "        book.save(file_name)\n",
    "        print(\"Data has been successfully written to the Excel file without duplicates.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the Excel file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Upload the updated file back to SharePoint\n",
    "    try:\n",
    "        with open(file_name, 'rb') as content_file:\n",
    "            file_content = content_file.read()\n",
    "\n",
    "        File.save_binary(ctx, f\"{doc_library}/{file_name}\", file_content)\n",
    "        print(\"File has been uploaded back to SharePoint.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during file upload: {e}\")\n",
    "\n",
    "# Cleanup: Remove the local file\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "    print(\"Local file has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec58237-4cfa-41f0-9da5-380aef60a47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
